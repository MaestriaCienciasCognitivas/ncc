
<!DOCTYPE html>


<html lang="es" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Cuaderno 5: Perceptrones &#8212; Neurociencia Cognitiva y Computacional</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=78d55cf8"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/translations.js?v=d190bf04"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/S5_Cuaderno5';</script>
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Búsqueda" href="../search.html" />
    <link rel="next" title="Práctico 4: Redes convolucionales" href="S5_Practico4.html" />
    <link rel="prev" title="Práctico 3: Modelos de memorias matriciales" href="S4_Practico3.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="es"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Saltar al contenido principal</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Volver arriba</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Advertencia de versión"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Neurociencia Cognitiva y Computacional - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Neurociencia Cognitiva y Computacional - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Búsqueda</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introducción
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Taller de Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S1_Cuaderno1.html">Cuaderno 1: Introducción a Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="S1_Cuaderno2.html">Cuaderno 2: NumPy y Matplotlib</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modelos de neuronas</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S2-modelos-neuronas.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S2_Cuaderno3.html">Cuaderno 3: Métodos numéricos</a></li>
<li class="toctree-l1"><a class="reference internal" href="S2_Practico1.html">Práctico 1: Ecuación de Hodgkin-Huxley</a></li>
<li class="toctree-l1"><a class="reference internal" href="S3_Practico2a.html">Práctico 2a: Neurona de Wilson</a></li>
<li class="toctree-l1"><a class="reference internal" href="S3_Practico2b.html">Práctico 2b: Leaky Integrate and Fire</a></li>
<li class="toctree-l1"><a class="reference internal" href="S3_Practico2c.html">Práctico 2c: Neurona de Izhikevich</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Redes neuronales</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S4-redes-neuronales.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S4_Cuaderno4.html">Cuaderno 4: Regla de Oja</a></li>
<li class="toctree-l1"><a class="reference internal" href="S4_Practico3.html">Práctico 3: Modelos de memorias matriciales</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje supervisado</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Cuaderno 5: Perceptrones</a></li>
<li class="toctree-l1"><a class="reference internal" href="S5_Practico4.html">Práctico 4: Redes convolucionales</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Redes biológicas</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S7_Cuaderno6.html">Cuaderno 6: Convoluciones</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Aprendizaje por refuerzo</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S8-aprendizaje-refuerzo.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S8_Practico5.html">Práctico 5: Taxi</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Campos receptivos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S9-campos-receptivos.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S9_Practico6.html">Práctico 6: Campos receptivos</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Control motor</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S10-control-motor.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S10_Practico7.html">Práctico 7: Generadores centrales de patrones (CPGs)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Oscilaciones</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../S11-oscilaciones.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="S11_Cuaderno7.html">Cuaderno 7: Densidad Espectral de Potencia</a></li>
<li class="toctree-l1"><a class="reference internal" href="S11_Practico8.html">Práctico 8: Exploración de una oscilación neural</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Atención</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S12_Practico9.html">Práctico 9: Redes atencionales</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cognición numérica</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="S13_Practico10.html">Práctico 10: Cognición numérica</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/MaestriaCienciasCognitivas/ncc/blob/main/book/notebooks/S5_Cuaderno5.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MaestriaCienciasCognitivas/ncc" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Repositorio de origen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MaestriaCienciasCognitivas/ncc/issues/new?title=Issue%20on%20page%20%2Fnotebooks/S5_Cuaderno5.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Abrir un problema"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Descarga esta pagina">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/S5_Cuaderno5.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Descargar archivo fuente"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Imprimir en PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modo de pantalla completa"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="claro/oscuro" aria-label="claro/oscuro" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Cuaderno 5: Perceptrones</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenido </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuracion">Configuración</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funciones-de-graficado">Funciones de graficado</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron-simple">Perceptrón simple</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-del-perceptron">Componentes del perceptrón</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-matematico">Modelo matemático</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-activacion-sigma">Función de activación <span class="math notranslate nohighlight">\(\sigma\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-or">Compuerta OR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-and">Compuerta AND</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-xor">Compuerta XOR</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron-multicapa">Perceptrón multicapa</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-dataset-mnist">El dataset MNIST</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-los-digitos">Visualización de los dígitos</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="cuaderno-5-perceptrones">
<h1>Cuaderno 5: Perceptrones<a class="headerlink" href="#cuaderno-5-perceptrones" title="Link to this heading">#</a></h1>
<p>Los <em>perceptrones</em> fueron introducidos por Frank Rosenblatt entre 1957 y 1962 como una familia de modelos teóricos y experimentales de redes neuronales artificiales. En su momento generaron mucho entusiasmo, pero también bastante controversia sobre sus alcances. A partir de ese trabajo surgieron modelos posteriores más abstractos y matemáticamente formales.</p>
<p>El antecedente directo fue la <strong>neurona de McCulloch y Pitts</strong> (1943), que proponía una neurona muy simplificada, pensada como un elemento de cálculo lógico. Esa idea abrió la puerta a imaginar redes de unidades elementales capaces de computar funciones más complejas.</p>
<p>Hoy en día, cuando decimos <em>perceptrón simple</em> solemos referirnos a un clasificador lineal de una sola capa (con una función de activación tipo escalón o sigmoide), y con <em>perceptrón multicapa</em> (MLP, <em>multilayer perceptron</em>) a una red de retroalimentación (<em>feedforward</em>) con al menos una capa oculta y entrenada mediante retropropagación (un algoritmo que recién se popularizó en los años 80).</p>
<p>Aunque la inspiración inicial vino de la biología, las redes neuronales modernas abstraen mucho esos detalles y se piensan más como funciones matemáticas: cada capa aplica una transformación lineal seguida de una no linealidad. En ese sentido, comparten gran parte de la matemática con la <strong>regresión logística</strong>.</p>
<p>La diferencia es que las redes neuronales son más poderosas: se ha demostrado que un perceptrón multicapa con una sola capa oculta y suficientes neuronas puede aproximar cualquier función continua en un dominio acotado (esto se conoce como el <strong>teorema de aproximación universal</strong>).</p>
<section id="configuracion">
<h2>Configuración<a class="headerlink" href="#configuracion" title="Link to this heading">#</a></h2>
<p>Como es usual, comenzamos importando las librerías que vamos a utilizar. Corré las celdas en esta sección para cargar las funciones que vamos a usar en el cuaderno.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ipywidgets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">widgets</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sklearn</span>
</pre></div>
</div>
</div>
</div>
<section id="funciones-de-graficado">
<h3>Funciones de graficado<a class="headerlink" href="#funciones-de-graficado" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">visualizar_errores</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">errors</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iteración&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">visualizar_pesos</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">titulo</span><span class="o">=</span><span class="s2">&quot;Límites de decisión&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    W: (2,) o (k,2)  pesos [w1, w2] por neurona</span>
<span class="sd">    b: escalar o (k,1)/(k,)  sesgo por neurona</span>
<span class="sd">    X, Y: opcionales para plotear puntos del dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

    <span class="c1"># Normalizar formas</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>           <span class="c1"># -&gt; (k,2)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">W</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># -&gt; (k,1)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="c1"># si vino transpuesto, intentamos acomodar</span>
            <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">T</span>
        <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Rango amigable para entradas binarias</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>

    <span class="c1"># Dibujar una recta por neurona: w1*x + w2*y + b = 0  -&gt; y = -(w1*x + b)/w2</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">wi</span><span class="p">,</span> <span class="n">bi</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">wi</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">1e-12</span><span class="p">:</span>
            <span class="n">y_vals</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">wi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x_vals</span> <span class="o">+</span> <span class="n">bi</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">/</span> <span class="n">wi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;neurona </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># frontera vertical: x = -b/w1</span>
            <span class="n">x0</span> <span class="o">=</span> <span class="o">-</span><span class="n">bi</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">wi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;neurona </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Puntos del dataset (si se pasan)</span>
    <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">yy</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">yy</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">yy</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Clase 0&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">yy</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">yy</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Clase 1&#39;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titulo</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="perceptron-simple">
<h2>Perceptrón simple<a class="headerlink" href="#perceptron-simple" title="Link to this heading">#</a></h2>
<p>El primer problema de nuestro perceptrón va a ser el de aprender a imitar una compuerta lógica <strong>OR</strong>.<br />
Las compuertas OR son dispositivos electrónicos con una función booleana que devuelve 1 cuando al menos una de sus dos entradas está prendida.</p>
<p>El objetivo del perceptrón va a ser, a partir de dos entradas binarias y una salida esperada, ajustar los pesos de su capa de activación de manera que, tras entrenarse varias veces, siempre pueda reproducir la función booleana OR.</p>
<p>En este caso, vamos a entrenar un perceptrón de dos nodos de entrada y uno de salida con los siguientes pares de ejemplo:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\mathbf{X}_1 = \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \; \mathbf{Y}_1 = \begin{pmatrix} 0 \end{pmatrix} \\
\mathbf{X}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}, \; \mathbf{Y}_2 = \begin{pmatrix} 1 \end{pmatrix} \\
\mathbf{X}_3 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}, \; \mathbf{Y}_3 = \begin{pmatrix} 1 \end{pmatrix} \\
\mathbf{X}_4 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}, \; \mathbf{Y}_4 = \begin{pmatrix} 1 \end{pmatrix}
\end{split}
\end{split}\]</div>
<p>Para expresarlo de manera más compacta, podemos reunir todas las combinaciones en una matriz de entradas <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> y un vector de salidas <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X} =
\begin{pmatrix}
0 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 1 &amp; 0 &amp; 1
\end{pmatrix}, \quad
\mathbf{Y} =
\begin{pmatrix}
0 &amp; 1 &amp; 1 &amp; 1
\end{pmatrix}
\end{split}\]</div>
<p>De esta manera el perceptrón ve <strong>todas las posibles combinaciones</strong> de las dos entradas y la salida esperada correspondiente.</p>
<section id="componentes-del-perceptron">
<h3>Componentes del perceptrón<a class="headerlink" href="#componentes-del-perceptron" title="Link to this heading">#</a></h3>
<p>Un perceptrón simple tiene tres elementos básicos:</p>
<ul class="simple">
<li><p><strong>Entradas:</strong> los valores que alimentan al perceptrón (acá, dos bits de entrada).</p></li>
<li><p><strong>Pesos:</strong> cada entrada tiene un peso asociado que indica su importancia relativa. Estos pesos se ajustan durante el entrenamiento.</p></li>
<li><p><strong>Función de activación:</strong> después de calcular la suma ponderada <span class="math notranslate nohighlight">\(z\)</span>, se aplica una función que decide si la neurona se “activa” o no.</p></li>
</ul>
</section>
<section id="modelo-matematico">
<h3>Modelo matemático<a class="headerlink" href="#modelo-matematico" title="Link to this heading">#</a></h3>
<p>Podemos modelar los pesos con un vector columna <span class="math notranslate nohighlight">\(\mathbf{w} = (w_1, w_2)^\top\)</span>.<br />
Para un ejemplo de entrada <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2)^\top\)</span>, la salida lineal del perceptrón es:</p>
<div class="math notranslate nohighlight">
\[
z = \mathbf{w}^\top \mathbf{x} + b
\]</div>
<p>donde <span class="math notranslate nohighlight">\(b\)</span> es el <strong>sesgo</strong>, que permite desplazar la frontera de decisión.</p>
<p>Finalmente, este valor <span class="math notranslate nohighlight">\(z\)</span> se pasa por una función de activación no lineal. En el perceptrón original de Rosenblatt se usaba una <strong>función escalón</strong> (devuelve 0 o 1). En versiones modernas se usa a menudo la <strong>función sigmoide</strong>:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} = \sigma(w_1 x_1 + w_2 x_2 + b)
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\sigma\)</span> es la función sigmoide logística. El valor <span class="math notranslate nohighlight">\(\hat{y}\)</span> es la salida del perceptrón y se compara con la salida esperada <span class="math notranslate nohighlight">\(Y\)</span> para ajustar los pesos durante el entrenamiento.</p>
</section>
<section id="funcion-de-activacion-sigma">
<h3>Función de activación <span class="math notranslate nohighlight">\(\sigma\)</span><a class="headerlink" href="#funcion-de-activacion-sigma" title="Link to this heading">#</a></h3>
<p>La <strong>función de activación</strong> transforma el resultado de multiplicar las entradas por los pesos y sumar el sesgo en un valor no lineal. Esto es clave cuando queremos que el perceptrón tome una <strong>decisión binaria</strong>, como en problemas de clasificación.</p>
<p>Una función de activación muy usada es la <strong>sigmoide</strong> (aunque hay muchas otras):</p>
<div class="math notranslate nohighlight">
\[
\sigma(x) = \frac{1}{1 + e^{-\beta x + b}}
\]</div>
<p>Esta función devuelve valores en el rango <span class="math notranslate nohighlight">\((0,1)\)</span>, nunca exactamente 0 o 1, pero muy cercanos. Así podemos interpretar la salida como una <strong>probabilidad</strong> de que la neurona se active.</p>
<p>Ejecutá la celda siguiente para verla en acción, y pensá:</p>
<ul class="simple">
<li><p>¿Qué ocurre cuando aumenta <span class="math notranslate nohighlight">\(\beta\)</span>?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">beta</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span> <span class="n">b</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "63fb44f2b59f4c8eb0d6c94004ffe687"}</script></div>
</div>
</section>
<section id="compuerta-or">
<h3>Compuerta OR<a class="headerlink" href="#compuerta-or" title="Link to this heading">#</a></h3>
<p>El entrenamiento del perceptrón se realiza utilizando un algoritmo conocido como regla de aprendizaje del perceptrón. Este ajusta los pesos basándose en el error de las predicciones, buscando minimizar la diferencia entre las salidas predichas y las reales. En la clase vimos como combinando el aprendizaje Hebbiano con la regla de la cadena podemos ir aproximandonos a los pesos que buscamos.</p>
<p>Veamos la implementación de un perceptrón simple y entrenémoslo para detectar la compuerta OR:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Umbral de activación</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Definimos el modelo lineal que queremos resolver</span>
<span class="k">def</span><span class="w"> </span><span class="nf">z</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">W</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># Definimos la función de activación</span>
<span class="k">def</span><span class="w"> </span><span class="nf">sigma</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sigma</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>

<span class="c1"># Definimos la derivada de la función de activación dy/dw</span>
<span class="k">def</span><span class="w"> </span><span class="nf">dg</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">y</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Definimos la función que calcula el error</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x_pred</span>

<span class="c1"># Definimos la funcion que entrena un conjunto de datos de entrada y salida y grafica el error cometido</span>
<span class="c1"># en cada salto de tiempo.</span>
<span class="c1"># X: Las entradas del conjunto de entrenamiento</span>
<span class="c1"># Y: Las salidas esperadas del conjunto de entrenamiento</span>
<span class="c1"># alpha: Constante de aprendizaje</span>
<span class="c1"># tmax: Tiempo máximo que queremos entrenar</span>
<span class="k">def</span><span class="w"> </span><span class="nf">perceptron_simple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># Iniciamos un array que va a guardar los errores en cada paso para poder graficarlos al final</span>
    <span class="c1"># y observar como va aprendiendo el perceptrón en cada paso</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Fijamos la semilla para reproducir siempre los mismos valores aleatorios</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> 
    
    <span class="c1"># Iniciamos la matriz con los pesos en forma aleatoria</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Iniciamos el término de sesgo con un número aleatorio</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Definimos la cantidad de trials que vamos a usar</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">tmax</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dg</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

        <span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">errors</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Graficamos el error</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">visualizar_errores</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span>
    <span class="n">visualizar_pesos</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Imprimimos los parámetros</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W =&quot;</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b =&quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Entrenamos al perceptrón para la funcion OR</span>
<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span> <span class="n">tmax</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">perceptron_simple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">tmax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "db4fb3ce593245138dd5db100250bf9f"}</script></div>
</div>
<p>Ejercitamos al perceptrón con dos valores de entrada:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">perceptron_simple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Salida: </span><span class="si">{</span><span class="n">y_hat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5fa8feebb76160b5fe6f28afcf182b6b4777bc6bfe380ae4508a9e1189d21f35.png" src="../_images/5fa8feebb76160b5fe6f28afcf182b6b4777bc6bfe380ae4508a9e1189d21f35.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W = [[2.15541611 0.84565936]]
b = -0.23629002610677718
Salida: [[1]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="compuerta-and">
<h3>Compuerta AND<a class="headerlink" href="#compuerta-and" title="Link to this heading">#</a></h3>
<p>En una forma similar, podemos entrenar al perceptrón para detectar cuando los dos nodos de entrada se activan al mismo tiempo. Esto puede ser visto como la función booleana AND. En este caso, los vectores de entrenamiento y de salida esperada pueden ser:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
\pmb{X_1} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} &amp; \pmb{Y_1} = \begin{pmatrix} 0 \end{pmatrix} \\
\pmb{X_2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} &amp; \pmb{Y_2} = \begin{pmatrix} 0 \end{pmatrix} \\
\pmb{X_3} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} &amp; \pmb{Y_3} = \begin{pmatrix} 0\end{pmatrix} \\
\pmb{X_4} = \begin{pmatrix} 1 \\ 1 \end{pmatrix} &amp; \pmb{Y_4} = \begin{pmatrix} 1 \end{pmatrix}
\end{split}\end{split}\]</div>
<p>Para hacerlo con nuestro código, no tenemos más que entrenar al perceptrón con las nuevas matrices:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">perceptron_simple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Salida: </span><span class="si">{</span><span class="n">y_hat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2849270af0ef971c7add0c3064c50c576b8ab33bfd568e8c454a4c5890425212.png" src="../_images/2849270af0ef971c7add0c3064c50c576b8ab33bfd568e8c454a4c5890425212.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W = [[4.66792918 4.66792605]]
b = -7.099115644806799
Salida: [[0]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="compuerta-xor">
<h3>Compuerta XOR<a class="headerlink" href="#compuerta-xor" title="Link to this heading">#</a></h3>
<p>Veamos ahora la compuerta XOR. Esta compuerta, también conocida como compuerta OR exclusiva, detecta cuando una entrada esta activa, pero no la otra. Para resolver este caso, los vectores de entrenamiento y de salida esperada pueden ser:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}
\pmb{X_1} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} &amp; \pmb{Y_1} = \begin{pmatrix} 0 \end{pmatrix} \\
\pmb{X_2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} &amp; \pmb{Y_2} = \begin{pmatrix} 1 \end{pmatrix} \\
\pmb{X_3} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} &amp; \pmb{Y_3} = \begin{pmatrix} 1 \end{pmatrix} \\
\pmb{X_3} = \begin{pmatrix} 1 \\ 1 \end{pmatrix} &amp; \pmb{Y_4} = \begin{pmatrix} 0 \end{pmatrix}
\end{split}\end{split}\]</div>
<p>Este problema de apariencia inocente es difícil porque no es linealmente separable. Si ponemos las cuatro posibles entradas en un plano, no hay ninguna línea recta que separe los casos que tienen que dar 1 de los casos que tienen que dar 0.
Vamos a comparar a una red de 2 entradas y una salida que entrenamos con la regla delta y a una red que como la presentada más arriba, además de las 2 entradas y la salida tiene dos unidades en la capa oculta.</p>
<p><em>Ejercicio: Entrenar al perceptrón con estos vectores de entrenamiento y de salida esperados.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Entrenamos al perceptrón para la funcion XOR</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">perceptron_simple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Salida: </span><span class="si">{</span><span class="n">y_hat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/37640cd376e5c4af37c5bdb1adceb1f7930e232b7db33399141becd1db60d732.png" src="../_images/37640cd376e5c4af37c5bdb1adceb1f7930e232b7db33399141becd1db60d732.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W = [[1.72833445e-09 1.72822386e-09]]
b = -2.0499821978825494e-09
Salida: [[0]]
</pre></div>
</div>
</div>
</div>
<p>No es posible construir un perceptrón de una sola capa que compute la operación lógica <strong>XOR</strong>. En su libro <em>Perceptrons</em> (1969), Marvin Minsky y Seymour Papert demostraron varios teoremas sobre las limitaciones de estos modelos, entre ellos que no podían implementar funciones como la exclusión OR (XOR), la paridad o la conectividad.</p>
<p>La intuición es que un perceptrón simple es un <strong>clasificador lineal</strong>. Para dos entradas, la ecuación</p>
<div class="math notranslate nohighlight">
\[
w_1 x_1 + w_2 x_2 + b = 0
\]</div>
<p>describe una recta que actúa como frontera de decisión: todos los puntos de un lado se clasifican como 0 y todos los del otro como 1.</p>
<p>El problema es que la función XOR <strong>no es linealmente separable</strong>: no existe una sola recta que divida el plano en las dos categorías correctas. Para lograrlo hacen falta múltiples rectas combinadas, es decir, <strong>una red con al menos una capa oculta</strong> (un perceptrón multicapa).</p>
</section>
</section>
<section id="perceptron-multicapa">
<h2>Perceptrón multicapa<a class="headerlink" href="#perceptron-multicapa" title="Link to this heading">#</a></h2>
<p>Los resultados de Minsky y Papert (1969) se aplicaban únicamente a perceptrones de <strong>una sola capa</strong>.<br />
En 1974, Paul Werbos presentó en su tesis doctoral un procedimiento general para ajustar adaptativamente los pesos de un sistema no lineal diferenciable, calculando derivadas desde las salidas hacia las entradas.<br />
Este algoritmo, conocido como <strong>retropropagación del error</strong> (<em>backpropagation</em>), permite entrenar perceptrones multicapa mediante descenso por gradiente y muestras de entrenamiento.<br />
El trabajo se difundió masivamente recién en 1986, gracias a Rumelhart, Hinton y Williams.</p>
<p>El <strong>perceptrón multicapa (MLP)</strong> agrega una o más <strong>capas ocultas</strong> ((h), por <em>hidden</em>) conformadas por un número arbitrario de nodos ubicados entre la capa de entrada y la de salida.<br />
Los nodos de salida ya no reciben directamente las entradas originales, sino las activaciones de la capa oculta.</p>
<p>Un MLP con una sola capa oculta debe aprender dos matrices de pesos y dos sesgos:</p>
<ul class="simple">
<li><p>(W_h, b_h): conectan la entrada con la capa oculta.</p></li>
<li><p>(W_y, b_y): conectan la capa oculta con la salida.</p></li>
</ul>
<p>De esta forma, la salida de la red se define como:</p>
<div class="math notranslate nohighlight">
\[
\hat{y} \;=\; \sigma\!\big(W_y \, \sigma(W_h X + b_h) + b_y\big)
\]</div>
<p>donde (\sigma) es la función de activación (sigmoide, tanh, ReLU u otra).<br />
La retropropagación permite ajustar estos parámetros para que la salida (\hat{y}) se aproxime cada vez más a la salida esperada.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definimos la funcion que entrena un conjunto de datos de entrada y salida y grafica el error cometido</span>
<span class="c1"># en cada salto de tiempo.</span>
<span class="c1"># X: Las entradas del conjunto de entrenamiento</span>
<span class="c1"># Y: Las salidas esperadas del conjunto de entrenamiento</span>
<span class="c1"># nodos_capa_oculta: Cantidad de nodos en la capa oculta</span>
<span class="c1"># tmax: Tiempo máximo que queremos entrenar</span>
<span class="c1"># alpha: Constante de aprendizaje</span>
<span class="k">def</span><span class="w"> </span><span class="nf">perceptron_multicapa</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nodos_capa_oculta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># Iniciamos un array que va a guardar los errores en cada paso para poder graficarlos al final</span>
    <span class="c1"># y observar como va aprendiendo el perceptrón en cada paso</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Fijamos la semilla para reproducir siempre los mismos valores aleatorios</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> 

    <span class="c1"># Iniciamos la matriz con los pesos de la capa de salida en forma aleatoria</span>
    <span class="n">W_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nodos_capa_oculta</span><span class="p">)</span>

    <span class="c1"># Iniciamos la matriz con los pesos de la capa oculta en forma aleatoria</span>
    <span class="n">W_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">nodos_capa_oculta</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Iniciamos los términos de sesgo para la capta de salida y la capa oculta con números aleatorios</span>
    <span class="n">b_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">nodos_capa_oculta</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Definimos la cantidad de trials que vamos a usar</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">tmax</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>       
        <span class="n">h</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">)</span>
        <span class="n">h_hat</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">)</span>
        
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y</span><span class="p">(</span><span class="n">h_hat</span><span class="p">,</span> <span class="n">W_y</span><span class="p">,</span> <span class="n">b_y</span><span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        
        <span class="n">delta_y</span> <span class="o">=</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dg</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">delta_h</span> <span class="o">=</span> <span class="n">W_y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta_y</span><span class="p">)</span> <span class="o">*</span> <span class="n">dg</span><span class="p">(</span><span class="n">h_hat</span><span class="p">)</span>
        
        <span class="n">W_h</span> <span class="o">=</span> <span class="n">W_h</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_h</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">W_y</span> <span class="o">=</span> <span class="n">W_y</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_y</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h_hat</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        
        <span class="n">b_y</span> <span class="o">=</span> <span class="n">b_y</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_y</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">b_h</span> <span class="o">=</span> <span class="n">b_h</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_h</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">errors</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Graficamos el error</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">visualizar_errores</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span>
    <span class="n">visualizar_pesos</span><span class="p">(</span><span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># Imprimimos los parámetros</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W_h =&quot;</span><span class="p">,</span> <span class="n">W_h</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b_h =&quot;</span><span class="p">,</span> <span class="n">b_h</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W_y =&quot;</span><span class="p">,</span> <span class="n">W_y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b_y =&quot;</span><span class="p">,</span> <span class="n">b_y</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">),</span> <span class="n">W_y</span><span class="p">,</span> <span class="n">b_y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Entrenamos al perceptrón para la funcion OR, tm</span>
<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">nodos_capa_oculta</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">tmax</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">simulate</span><span class="p">(</span><span class="n">nodos_capa_oculta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">perceptron_multicapa</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nodos_capa_oculta</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">tmax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "57dece1908fc4199983c71c13d0d8639"}</script></div>
</div>
<p>Ejercitamos la red aprendida con un conjunto de entradas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Entrenamos al perceptrón para la funcion XOR</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">perceptron_multicapa</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Salida: </span><span class="si">{</span><span class="n">y_hat</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/613c06f699ae781826507780678188818caaad2c5ed9b469d23cfe82a3c68251.png" src="../_images/613c06f699ae781826507780678188818caaad2c5ed9b469d23cfe82a3c68251.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W_h = [[-3.93392725  3.61734321]
 [ 4.88412946 -4.97588572]]
b_h = [[-2.00555666]
 [-2.98474798]]
W_y = [[5.46139184 5.49855889]]
b_y = -2.6989723505622845
Salida: [[1]]
</pre></div>
</div>
</div>
</div>
<p>Se ha demostrado que las redes neuronales <em>feedforward</em> multicapa con un número suficiente de unidades ocultas entre las unidades de entrada y salida tienen una propiedad de aproximación universal: «pueden aproximar prácticamente cualquier función de interés con el grado de precisión deseado» (Hornik et al. 1989).</p>
</section>
<section id="el-dataset-mnist">
<h2>El dataset MNIST<a class="headerlink" href="#el-dataset-mnist" title="Link to this heading">#</a></h2>
<p>Hasta ahora trabajamos con ejemplos muy simples de compuertas lógicas. Para dar un paso más, vamos a aplicar perceptrones al conjunto de datos <strong>MNIST</strong> (<em>Modified National Institute of Standards and Technology database</em>), un clásico en el área de aprendizaje automático.</p>
<p>MNIST contiene <strong>70.000 imágenes en escala de grises de dígitos manuscritos (0–9)</strong>, cada una de <strong>28×28 píxeles</strong>. Es un benchmark muy usado porque es suficientemente grande y variado para poner a prueba modelos de clasificación, pero al mismo tiempo es manejable en una computadora personal.</p>
<p>En nuestro caso vamos a:</p>
<ul class="simple">
<li><p>Descargar el dataset directamente con <code class="docutils literal notranslate"><span class="pre">fetch_openml</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code>.</p></li>
<li><p>Normalizar los valores de los píxeles al rango <span class="math notranslate nohighlight">\([0,1]\)</span>.</p></li>
<li><p>Codificar las etiquetas de salida en formato <strong>one-hot</strong>: cada dígito (0–9) se representa como un vector de 10 posiciones con un único 1 en la posición correspondiente.</p></li>
</ul>
<p>De esta manera, <span class="math notranslate nohighlight">\(X\)</span> contendrá todas las imágenes como vectores de 784 características (28×28), y <span class="math notranslate nohighlight">\(Y\)</span> contendrá los vectores one-hot con las etiquetas de los dígitos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">digits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">digits</span><span class="p">[</span><span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mnist</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:109: UserWarning: A network error occurred while downloading https://api.openml.org/api/v1/json/data/list/data_name/mnist_784/limit/2/data_version/1. Retrying...
  warn(
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ConnectionRefusedError</span><span class="g g-Whitespace">                    </span>Traceback (most recent call last)
<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:1319,</span> in <span class="ni">AbstractHTTPHandler.do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1318</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1319</span>     <span class="n">h</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">get_method</span><span class="p">(),</span> <span class="n">req</span><span class="o">.</span><span class="n">selector</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>               <span class="n">encode_chunked</span><span class="o">=</span><span class="n">req</span><span class="o">.</span><span class="n">has_header</span><span class="p">(</span><span class="s1">&#39;Transfer-encoding&#39;</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span> <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1338,</span> in <span class="ni">HTTPConnection.request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1337</span><span class="w"> </span><span class="sd">&quot;&quot;&quot;Send a complete request to the server.&quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1338</span> <span class="bp">self</span><span class="o">.</span><span class="n">_send_request</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1384,</span> in <span class="ni">HTTPConnection._send_request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1383</span>     <span class="n">body</span> <span class="o">=</span> <span class="n">_encode</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="s1">&#39;body&#39;</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1384</span> <span class="bp">self</span><span class="o">.</span><span class="n">endheaders</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1333,</span> in <span class="ni">HTTPConnection.endheaders</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1332</span>     <span class="k">raise</span> <span class="n">CannotSendHeader</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">1333</span> <span class="bp">self</span><span class="o">.</span><span class="n">_send_output</span><span class="p">(</span><span class="n">message_body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1093,</span> in <span class="ni">HTTPConnection._send_output</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1092</span> <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">[:]</span>
<span class="ne">-&gt; </span><span class="mi">1093</span> <span class="bp">self</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1095</span> <span class="k">if</span> <span class="n">message_body</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1096</span> 
<span class="g g-Whitespace">   </span><span class="mi">1097</span>     <span class="c1"># create a consistent interface to message_body</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1037,</span> in <span class="ni">HTTPConnection.send</span><span class="nt">(self, data)</span>
<span class="g g-Whitespace">   </span><span class="mi">1036</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">auto_open</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1037</span>     <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1038</span> <span class="k">else</span><span class="p">:</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1472,</span> in <span class="ni">HTTPSConnection.connect</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1470</span> <span class="s2">&quot;Connect to a host on a given (SSL) port.&quot;</span>
<span class="ne">-&gt; </span><span class="mi">1472</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1474</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tunnel_host</span><span class="p">:</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\http\client.py:1003,</span> in <span class="ni">HTTPConnection.connect</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1002</span> <span class="n">sys</span><span class="o">.</span><span class="n">audit</span><span class="p">(</span><span class="s2">&quot;http.client.connect&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">host</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">port</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1003</span> <span class="bp">self</span><span class="o">.</span><span class="n">sock</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_connection</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1004</span>     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">host</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">port</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">source_address</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1005</span> <span class="c1"># Might fail in OSs that don&#39;t implement TCP_NODELAY</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\socket.py:864,</span> in <span class="ni">create_connection</span><span class="nt">(address, timeout, source_address, all_errors)</span>
<span class="g g-Whitespace">    </span><span class="mi">863</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">all_errors</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">864</span>     <span class="k">raise</span> <span class="n">exceptions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">865</span> <span class="k">raise</span> <span class="n">ExceptionGroup</span><span class="p">(</span><span class="s2">&quot;create_connection failed&quot;</span><span class="p">,</span> <span class="n">exceptions</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\socket.py:849,</span> in <span class="ni">create_connection</span><span class="nt">(address, timeout, source_address, all_errors)</span>
<span class="g g-Whitespace">    </span><span class="mi">848</span>     <span class="n">sock</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">source_address</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">849</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">sa</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">850</span> <span class="c1"># Break explicitly a reference cycle</span>

<span class="ne">ConnectionRefusedError</span>: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">URLError</span><span class="g g-Whitespace">                                  </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">digits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\utils\_param_validation.py:218,</span> in <span class="ni">validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">212</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">213</span>     <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>         <span class="n">skip_parameter_validation</span><span class="o">=</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span>             <span class="n">prefer_skip_nested_validation</span> <span class="ow">or</span> <span class="n">global_skip_validation</span>
<span class="g g-Whitespace">    </span><span class="mi">216</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>     <span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">218</span>         <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">219</span> <span class="k">except</span> <span class="n">InvalidParameterError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="c1"># When the function is just a wrapper around an estimator, we allow</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>     <span class="c1"># the function to delegate validation to the estimator, but we replace</span>
<span class="g g-Whitespace">    </span><span class="mi">222</span>     <span class="c1"># the name of the estimator by the name of the function in the error</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span>     <span class="c1"># message to avoid confusion.</span>
<span class="g g-Whitespace">    </span><span class="mi">224</span>     <span class="n">msg</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">225</span>         <span class="sa">r</span><span class="s2">&quot;parameter of \w+ must be&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">226</span>         <span class="sa">f</span><span class="s2">&quot;parameter of </span><span class="si">{</span><span class="n">func</span><span class="o">.</span><span class="vm">__qualname__</span><span class="si">}</span><span class="s2"> must be&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">227</span>         <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">228</span>     <span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:1016,</span> in <span class="ni">fetch_openml</span><span class="nt">(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1010</span>     <span class="k">if</span> <span class="n">data_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1011</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1012</span>             <span class="s2">&quot;Dataset data_id=</span><span class="si">{}</span><span class="s2"> and name=</span><span class="si">{}</span><span class="s2"> passed, but you can only &quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1013</span>             <span class="s2">&quot;specify a numeric data_id or a name, not &quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1014</span>             <span class="s2">&quot;both.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data_id</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1015</span>         <span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1016</span>     <span class="n">data_info</span> <span class="o">=</span> <span class="n">_get_data_info_by_name</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1017</span>         <span class="n">name</span><span class="p">,</span> <span class="n">version</span><span class="p">,</span> <span class="n">data_home</span><span class="p">,</span> <span class="n">n_retries</span><span class="o">=</span><span class="n">n_retries</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="n">delay</span>
<span class="g g-Whitespace">   </span><span class="mi">1018</span>     <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1019</span>     <span class="n">data_id</span> <span class="o">=</span> <span class="n">data_info</span><span class="p">[</span><span class="s2">&quot;did&quot;</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1020</span> <span class="k">elif</span> <span class="n">data_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1021</span>     <span class="c1"># from the previous if statement, it is given that name is None</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:334,</span> in <span class="ni">_get_data_info_by_name</span><span class="nt">(name, version, data_home, n_retries, delay)</span>
<span class="g g-Whitespace">    </span><span class="mi">332</span> <span class="n">url</span> <span class="o">=</span> <span class="p">(</span><span class="n">_SEARCH_NAME</span> <span class="o">+</span> <span class="s2">&quot;/data_version/</span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">version</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">333</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">334</span>     <span class="n">json_data</span> <span class="o">=</span> <span class="n">_get_json_content_from_openml_api</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">335</span>         <span class="n">url</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">336</span>         <span class="n">error_message</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">337</span>         <span class="n">data_home</span><span class="o">=</span><span class="n">data_home</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">338</span>         <span class="n">n_retries</span><span class="o">=</span><span class="n">n_retries</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">339</span>         <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">340</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">341</span> <span class="k">except</span> <span class="n">OpenMLError</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">342</span>     <span class="c1"># we can do this in 1 function call if OpenML does not require the</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span>     <span class="c1"># specification of the dataset status (i.e., return datasets with a</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span>     <span class="c1"># given name / version regardless of active, deactivated, etc. )</span>
<span class="g g-Whitespace">    </span><span class="mi">345</span>     <span class="c1"># TODO: feature request OpenML.</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>     <span class="n">url</span> <span class="o">+=</span> <span class="s2">&quot;/status/deactivated&quot;</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:251,</span> in <span class="ni">_get_json_content_from_openml_api</span><span class="nt">(url, error_message, data_home, n_retries, delay)</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>         <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">251</span>     <span class="k">return</span> <span class="n">_load_json</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span> <span class="k">except</span> <span class="n">HTTPError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>     <span class="c1"># 412 is an OpenML specific error code, indicating a generic error</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>     <span class="c1"># (e.g., data not found)</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span>     <span class="k">if</span> <span class="n">error</span><span class="o">.</span><span class="n">code</span> <span class="o">!=</span> <span class="mi">412</span><span class="p">:</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:66,</span> in <span class="ni">_retry_with_clean_cache.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">     </span><span class="mi">64</span>     <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">66</span>     <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span> <span class="k">except</span> <span class="n">URLError</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">68</span>     <span class="k">raise</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:246,</span> in <span class="ni">_get_json_content_from_openml_api.&lt;locals&gt;._load_json</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span> <span class="nd">@_retry_with_clean_cache</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data_home</span><span class="o">=</span><span class="n">data_home</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">244</span> <span class="k">def</span><span class="w"> </span><span class="nf">_load_json</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span>     <span class="k">with</span> <span class="n">closing</span><span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">246</span>         <span class="n">_open_openml_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data_home</span><span class="p">,</span> <span class="n">n_retries</span><span class="o">=</span><span class="n">n_retries</span><span class="p">,</span> <span class="n">delay</span><span class="o">=</span><span class="n">delay</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">247</span>     <span class="p">)</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">248</span>         <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:178,</span> in <span class="ni">_open_openml_url</span><span class="nt">(url, data_home, n_retries, delay)</span>
<span class="g g-Whitespace">    </span><span class="mi">171</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span>     <span class="c1"># Create a tmpdir as a subfolder of dir_name where the final file will</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span>     <span class="c1"># be moved to if the download is successful. This guarantees that the</span>
<span class="g g-Whitespace">    </span><span class="mi">174</span>     <span class="c1"># renaming operation to the final location is atomic to ensure the</span>
<span class="g g-Whitespace">    </span><span class="mi">175</span>     <span class="c1"># concurrence safety of the dataset caching mechanism.</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span>     <span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_name</span><span class="p">)</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span>         <span class="k">with</span> <span class="n">closing</span><span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">178</span>             <span class="n">_retry_on_network_error</span><span class="p">(</span><span class="n">n_retries</span><span class="p">,</span> <span class="n">delay</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">full_url</span><span class="p">)(</span><span class="n">urlopen</span><span class="p">)(</span>
<span class="g g-Whitespace">    </span><span class="mi">179</span>                 <span class="n">req</span>
<span class="g g-Whitespace">    </span><span class="mi">180</span>             <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>         <span class="p">)</span> <span class="k">as</span> <span class="n">fsrc</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">182</span>             <span class="n">opener</span><span class="p">:</span> <span class="n">Callable</span>
<span class="g g-Whitespace">    </span><span class="mi">183</span>             <span class="k">if</span> <span class="n">is_gzip_encoded</span><span class="p">(</span><span class="n">fsrc</span><span class="p">):</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\site-packages\sklearn\datasets\_openml.py:102,</span> in <span class="ni">_retry_on_network_error.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">100</span> <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">101</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">102</span>         <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">103</span>     <span class="k">except</span> <span class="p">(</span><span class="n">URLError</span><span class="p">,</span> <span class="ne">TimeoutError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span>         <span class="c1"># 412 is a specific OpenML error code.</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span>         <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">HTTPError</span><span class="p">)</span> <span class="ow">and</span> <span class="n">e</span><span class="o">.</span><span class="n">code</span> <span class="o">==</span> <span class="mi">412</span><span class="p">:</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:189,</span> in <span class="ni">urlopen</span><span class="nt">(url, data, timeout, context)</span>
<span class="g g-Whitespace">    </span><span class="mi">187</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">188</span>     <span class="n">opener</span> <span class="o">=</span> <span class="n">_opener</span>
<span class="ne">--&gt; </span><span class="mi">189</span> <span class="k">return</span> <span class="n">opener</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">timeout</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:489,</span> in <span class="ni">OpenerDirector.open</span><span class="nt">(self, fullurl, data, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">486</span>     <span class="n">req</span> <span class="o">=</span> <span class="n">meth</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">488</span> <span class="n">sys</span><span class="o">.</span><span class="n">audit</span><span class="p">(</span><span class="s1">&#39;urllib.Request&#39;</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">full_url</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">get_method</span><span class="p">())</span>
<span class="ne">--&gt; </span><span class="mi">489</span> <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_open</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">491</span> <span class="c1"># post-process response</span>
<span class="g g-Whitespace">    </span><span class="mi">492</span> <span class="n">meth_name</span> <span class="o">=</span> <span class="n">protocol</span><span class="o">+</span><span class="s2">&quot;_response&quot;</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:506,</span> in <span class="ni">OpenerDirector._open</span><span class="nt">(self, req, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span>     <span class="k">return</span> <span class="n">result</span>
<span class="g g-Whitespace">    </span><span class="mi">505</span> <span class="n">protocol</span> <span class="o">=</span> <span class="n">req</span><span class="o">.</span><span class="n">type</span>
<span class="ne">--&gt; </span><span class="mi">506</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">handle_open</span><span class="p">,</span> <span class="n">protocol</span><span class="p">,</span> <span class="n">protocol</span> <span class="o">+</span>
<span class="g g-Whitespace">    </span><span class="mi">507</span>                           <span class="s1">&#39;_open&#39;</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">508</span> <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">509</span>     <span class="k">return</span> <span class="n">result</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:466,</span> in <span class="ni">OpenerDirector._call_chain</span><span class="nt">(self, chain, kind, meth_name, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">464</span> <span class="k">for</span> <span class="n">handler</span> <span class="ow">in</span> <span class="n">handlers</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">465</span>     <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">handler</span><span class="p">,</span> <span class="n">meth_name</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">466</span>     <span class="n">result</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">467</span>     <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">468</span>         <span class="k">return</span> <span class="n">result</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:1367,</span> in <span class="ni">HTTPSHandler.https_open</span><span class="nt">(self, req)</span>
<span class="g g-Whitespace">   </span><span class="mi">1366</span> <span class="k">def</span><span class="w"> </span><span class="nf">https_open</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">req</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1367</span>     <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_open</span><span class="p">(</span><span class="n">http</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">HTTPSConnection</span><span class="p">,</span> <span class="n">req</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1368</span>                         <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">)</span>

<span class="nn">File C:\Users\MARTN~1\miniconda3\envs\scratch\Lib\urllib\request.py:1322,</span> in <span class="ni">AbstractHTTPHandler.do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span>         <span class="n">h</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">get_method</span><span class="p">(),</span> <span class="n">req</span><span class="o">.</span><span class="n">selector</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>                   <span class="n">encode_chunked</span><span class="o">=</span><span class="n">req</span><span class="o">.</span><span class="n">has_header</span><span class="p">(</span><span class="s1">&#39;Transfer-encoding&#39;</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span>     <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>
<span class="ne">-&gt; </span><span class="mi">1322</span>         <span class="k">raise</span> <span class="n">URLError</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1323</span>     <span class="n">r</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">getresponse</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1324</span> <span class="k">except</span><span class="p">:</span>

<span class="ne">URLError</span>: &lt;urlopen error [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">digits</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="visualizacion-de-los-digitos">
<h3>Visualización de los dígitos<a class="headerlink" href="#visualizacion-de-los-digitos" title="Link to this heading">#</a></h3>
<p>Antes de entrenar una red neuronal, conviene explorar el dataset para hacernos una idea de cómo son las imágenes y sus etiquetas.<br />
Recordemos que cada ejemplo en <code class="docutils literal notranslate"><span class="pre">X</span></code> es un vector de 784 posiciones (los píxeles de una imagen 28×28 puestos en fila), y que la etiqueta correspondiente en <code class="docutils literal notranslate"><span class="pre">Y</span></code> está codificada en formato <em>one-hot</em>.</p>
<p>Para facilitar la inspección, vamos a usar un widget interactivo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">visualizar_digito</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y =&quot;</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Ejecutá la siguiente celda para definir el perceptrón multicapa. Es código es igual al anterior, con la novedad de que el entrenamiento lo haremos por lotes (<em>batches</em>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">g</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">sp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dg</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span>

<span class="c1"># Definimos la función que calcula el error</span>
<span class="k">def</span><span class="w"> </span><span class="nf">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_pred</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x_pred</span>

<span class="k">def</span><span class="w"> </span><span class="nf">z</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="n">W</span> <span class="o">+</span> <span class="n">b</span>

<span class="k">def</span><span class="w"> </span><span class="nf">perceptron_multicapa</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nodos_capa_oculta</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
  <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  
  <span class="n">N</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">nodos_capa_oculta</span>

  <span class="c1"># Pesos de la capa oculta</span>
  <span class="n">W_h</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="c1"># Pesos de la capa de salida</span>
  <span class="n">W_y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">H</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">b_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  
  <span class="c1"># Sesgos de la capa oculta</span>
  <span class="n">b_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

  <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">num_batches</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tmax</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">X_shuf</span><span class="p">,</span> <span class="n">Y_shuf</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_batches</span><span class="p">):</span>
      <span class="n">s</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">b</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">min</span><span class="p">((</span><span class="n">b</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
      <span class="n">Xb</span> <span class="o">=</span> <span class="n">X_shuf</span><span class="p">[</span><span class="n">s</span><span class="p">:</span><span class="n">e</span><span class="p">]</span>    <span class="c1"># (B, d)</span>
      <span class="n">Yb</span> <span class="o">=</span> <span class="n">Y_shuf</span><span class="p">[</span><span class="n">s</span><span class="p">:</span><span class="n">e</span><span class="p">]</span>    <span class="c1"># (B, k)</span>

      <span class="n">h_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">))</span>
      <span class="n">y_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">h_hat</span><span class="p">,</span> <span class="n">W_y</span><span class="p">,</span> <span class="n">b_y</span><span class="p">))</span>
      
      <span class="n">error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Yb</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>

      <span class="n">delta_y</span> <span class="o">=</span> <span class="n">error</span> <span class="o">*</span> <span class="n">dg</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
      <span class="n">delta_h</span> <span class="o">=</span> <span class="n">delta_y</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W_y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">dg</span><span class="p">(</span><span class="n">h_hat</span><span class="p">)</span>
      
      <span class="n">W_h</span> <span class="o">=</span> <span class="n">W_h</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">Xb</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta_h</span><span class="p">)</span>
      <span class="n">W_y</span> <span class="o">=</span> <span class="n">W_y</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">h_hat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta_y</span><span class="p">)</span>
      
      <span class="n">b_y</span> <span class="o">=</span> <span class="n">b_y</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_y</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">b_h</span> <span class="o">=</span> <span class="n">b_h</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta_h</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Validamos sobre todo el conjunto</span>
    <span class="n">h_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">))</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">h_hat</span><span class="p">,</span> <span class="n">W_y</span><span class="p">,</span> <span class="n">b_y</span><span class="p">))</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">error</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Época </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">tmax</span><span class="si">}</span><span class="s2"> - Loss: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

  <span class="c1"># Curva de error</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Época&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;MSE&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Entrenamiento&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_y</span><span class="p">,</span> <span class="n">b_y</span>
</pre></div>
</div>
</div>
</div>
<p>Ejecutá la celda siguiente para entrenarlo con el conjunto MNIST. Sé paciente, lleva tiempo ya que el entrenamiento se realiza en la CPU. Probá con 256 nodos en la capa oculta y un tmax de 25.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_r</span><span class="p">,</span> <span class="n">b_r</span> <span class="o">=</span> <span class="n">perceptron_multicapa</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">nodos_capa_oculta</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">tmax</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="k">def</span><span class="w"> </span><span class="nf">inferencia</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
  <span class="n">Xi</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="n">Yi</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  
  <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">Xi</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  
  <span class="n">h_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">Xi</span><span class="p">,</span> <span class="n">W_h</span><span class="p">,</span> <span class="n">b_h</span><span class="p">))</span>
  <span class="n">y_hat</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">z</span><span class="p">(</span><span class="n">h_hat</span><span class="p">,</span> <span class="n">W_r</span><span class="p">,</span> <span class="n">b_r</span><span class="p">))</span>
  
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Salida inferida:&quot;</span><span class="p">,</span> <span class="n">digits</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)])</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Salida esperada:&quot;</span><span class="p">,</span> <span class="n">Yi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="S4_Practico3.html"
       title="página anterior">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">anterior</p>
        <p class="prev-next-title">Práctico 3: Modelos de memorias matriciales</p>
      </div>
    </a>
    <a class="right-next"
       href="S5_Practico4.html"
       title="siguiente página">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title">Práctico 4: Redes convolucionales</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenido
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuracion">Configuración</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funciones-de-graficado">Funciones de graficado</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron-simple">Perceptrón simple</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-del-perceptron">Componentes del perceptrón</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-matematico">Modelo matemático</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-activacion-sigma">Función de activación <span class="math notranslate nohighlight">\(\sigma\)</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-or">Compuerta OR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-and">Compuerta AND</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compuerta-xor">Compuerta XOR</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perceptron-multicapa">Perceptrón multicapa</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#el-dataset-mnist">El dataset MNIST</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-los-digitos">Visualización de los dígitos</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Por Maestría en Ciencias Cognitivas
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>