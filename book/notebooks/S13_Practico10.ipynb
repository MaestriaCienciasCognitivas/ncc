{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae8e501-635c-43e2-9540-3724dfcfd3f3",
   "metadata": {},
   "source": [
    "# Práctico 10: Cognición numérica\n",
    "\n",
    "En este práctico intentaremos replicar los resultados reportados por Nasr y colaboradores (2019) usando una red convolucional profunda de menor tamaño reportada por Kubilius y cols. (2018) llamada _CORnet-Z_. La arquitectura de esta red intenta alinearse con la actividad neuronal de los humanos, de hecho, esta separada en áreas V1, V2, V4 e IT. Los autores del primer articulo utilizaron una red convolucional profunda más grande, pero también más dificil de entrenar, es por esto que optamos por utilizar una red más chica para comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f56dc0-d0f4-497c-be0e-98856aae55aa",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "\n",
    "Ejecutá todas las celdas de esta sección para importar las librerías y funciones que vamos a utilizar en el práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62970a95-1e92-48c0-87f3-59cee0e89e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, math, requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e96ae3-139a-4dbd-9b50-fd24d305103a",
   "metadata": {},
   "source": [
    "### Funciones utilitarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de6466-41b6-4707-a0fd-449c89b4ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_device():\n",
    "  if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "  elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "  else:\n",
    "    device = torch.device(\"cpu\")\n",
    "  print(\"Device encontrado:\", device)\n",
    "  return device\n",
    "\n",
    "def descargar_clases_imagenet()\n",
    "    url = 'https://raw.githubusercontent.com/MaestriaCienciasCognitivas/ncc/main/book/static/Practico10_Imagenet.json'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    clases = [v[1] for k, v in sorted(data.items(), key=lambda kv: int(kv[0]))]\n",
    "    return clases\n",
    "\n",
    "def muestrear_estandar(tam_imagen, num_objetos, radio_nominal, ruido_radio=0.1, distancia_min=5, margen=5, max_iter=10_000):\n",
    "    x, y, r = None, None, None\n",
    "    for i in range(num_objetos):\n",
    "        for j in range(max_iter):\n",
    "            ri = np.round(radio_nominal + ruido_radio * radio_nominal * np.random.normal()).astype(int)\n",
    "            xi = np.round(np.random.uniform(ri + margen, tam_imagen - ri - margen)).astype(int)\n",
    "            yi = np.round(np.random.uniform(ri + margen, tam_imagen - ri - margen)).astype(int)\n",
    "            if i == 0:\n",
    "                x, y, r = xi, yi, ri\n",
    "                break\n",
    "            else:\n",
    "                dists = np.sqrt((x - xi) ** 2 + (y - yi) ** 2)\n",
    "                if np.all(dists > r + ri + distancia_min):\n",
    "                    x = np.append(x, xi)\n",
    "                    y = np.append(y, yi)\n",
    "                    r = np.append(r, ri)\n",
    "                    break\n",
    "                if j == max_iter - 1:\n",
    "                    return None\n",
    "    return x, y, r\n",
    "\n",
    "def muestrear_area_constante(tam_imagen, num_objetos, area_total, **kwargs):\n",
    "    radio_nominal = np.sqrt(area_total / num_objetos / np.pi)\n",
    "    return muestrear_estandar(tam_imagen, num_objetos, radio_nominal, **kwargs)\n",
    "\n",
    "def muestrear_casco_convexo(tam_imagen, num_objetos, radio_nominal, ruido_radio=0.1, margen=5, distancia_min=5, max_iter=50_000, radio_casco=85, tam_hull=5):\n",
    "    x, y, r = None, None, None\n",
    "    cx = cy = tam_imagen / 2\n",
    "    theta_hull = np.arange(0, 2 * np.pi, (2 * np.pi) / tam_hull)\n",
    "    theta_hull += np.random.uniform(high=np.pi)\n",
    "    np.random.shuffle(theta_hull)\n",
    "    for i in range(num_objetos):\n",
    "        for j in range(max_iter):\n",
    "            if i < tam_hull:\n",
    "                theta = theta_hull[i]\n",
    "                radio = radio_casco + 5 * np.random.normal()\n",
    "            else:\n",
    "                theta = np.random.uniform(high=2 * np.pi)\n",
    "                radio = np.random.uniform(high=radio_casco - 2 * radio_nominal)\n",
    "            xi = np.round(cx + radio * np.cos(theta)).astype(int)\n",
    "            yi = np.round(cy + radio * np.sin(theta)).astype(int)\n",
    "            ri = np.round(radio_nominal + ruido_radio * radio_nominal * np.random.normal()).astype(int)\n",
    "            if i == 0:\n",
    "                x, y, r = xi, yi, ri\n",
    "                break\n",
    "            else:\n",
    "                dists = np.sqrt((x - xi) ** 2 + (y - yi) ** 2)\n",
    "                if np.all(dists > r + ri + distancia_min):\n",
    "                    x = np.append(x, xi)\n",
    "                    y = np.append(y, yi)\n",
    "                    r = np.append(r, ri)\n",
    "                    break\n",
    "                if j == max_iter - 1:\n",
    "                    return None\n",
    "    return x, y, r\n",
    "\n",
    "def verificar_densidad_control(x, y, r, dist_min=90, dist_max=100):\n",
    "    coords = np.concatenate((x[:, None], y[:, None]), axis=1)\n",
    "    dists = sp.spatial.distance.cdist(coords, coords, 'euclidean')\n",
    "    avg_dist = dists[np.triu_indices(len(x), 1)].mean()\n",
    "    return (avg_dist >= dist_min) & (avg_dist <= dist_max)\n",
    "\n",
    "def generar_fondo_uniforme(size, A):\n",
    "    h, w, ch = size\n",
    "    img = Image.new(\"L\", (w, h), color=A)\n",
    "    arr = np.array(img, dtype=np.uint8)\n",
    "    if ch == 1:\n",
    "        arr = arr[..., None]\n",
    "    elif ch == 3:\n",
    "        arr = np.repeat(arr[..., None], 3, axis=2)\n",
    "    return arr\n",
    "\n",
    "def dibujar_circulo(img, x, y, r):\n",
    "    if img.ndim == 3 and img.shape[2] == 1:\n",
    "        base = img[..., 0]\n",
    "    else:\n",
    "        base = img\n",
    "    pil_img = Image.fromarray(base)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    bbox = [x - r, y - r, x + r, y + r]\n",
    "    draw.ellipse(bbox, fill=255)\n",
    "    out = np.array(pil_img, dtype=np.uint8)\n",
    "    if img.ndim == 3 and img.shape[2] == 1:\n",
    "        out = out[..., None]\n",
    "    return out\n",
    "\n",
    "def dibujar_forma_aleatoria(img, x, y, r):\n",
    "    if img.ndim == 3 and img.shape[2] == 1:\n",
    "        base = img[..., 0]\n",
    "    else:\n",
    "        base = img\n",
    "    pil_img = Image.fromarray(base)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    ss = np.random.choice(range(4))\n",
    "    if ss == 0:  # círculo\n",
    "        bbox = [x - r, y - r, x + r, y + r]\n",
    "        draw.ellipse(bbox, fill=255)\n",
    "    elif ss == 1:  # rectángulo\n",
    "        r1 = int(np.random.uniform(0.7, 1.0) * r)\n",
    "        r2 = int(np.random.uniform(0.7, 1.0) * r)\n",
    "        draw.rectangle([x - r1, y - r2, x + r1, y + r2], fill=255)\n",
    "    elif ss == 2:  # elipse\n",
    "        r1 = int(np.random.uniform(0.3, 1.0) * r)\n",
    "        r2 = int(np.random.uniform(0.3, 1.0) * r)\n",
    "        bbox = [x - r1, y - r2, x + r1, y + r2]\n",
    "        draw.ellipse(bbox, fill=255)\n",
    "    elif ss == 3:  # triángulo\n",
    "        r1 = int(np.random.uniform(0.7, 1.0) * r)\n",
    "        r2 = int(np.random.uniform(0.7, 1.0) * r)\n",
    "        r3 = int(np.random.uniform(0.7, 1.0) * r)\n",
    "        pts = [(x + r1, y), (x, y - r2), (x - r3, y)]\n",
    "        draw.polygon(pts, fill=255)\n",
    "    out = np.array(pil_img, dtype=np.uint8)\n",
    "    if img.ndim == 3 and img.shape[2] == 1:\n",
    "        out = out[..., None]\n",
    "    return out\n",
    "\n",
    "def generar_conjunto(numerosidades, repeticiones, fn_muestreo, args_muestreo, fn_verificacion, fn_dibujo, tam_imagen, max_iter, nivel_fondo=50):\n",
    "    S, Q = [], []\n",
    "    for n in numerosidades:\n",
    "        for _ in range(repeticiones):\n",
    "            img = generar_fondo_uniforme((tam_imagen, tam_imagen, 1), A=nivel_fondo)\n",
    "            if n > 0:\n",
    "                for v in range(max_iter):\n",
    "                    x, y, r = fn_muestreo(tam_imagen, n, **args_muestreo)\n",
    "                    if n > 1:\n",
    "                        if fn_verificacion(x, y, r):\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                    if v == max_iter - 1:\n",
    "                        return None, None\n",
    "                if n == 1:\n",
    "                    x, y, r = [x], [y], [r]\n",
    "                for xi, yi, ri in zip(x, y, r):\n",
    "                    img = fn_dibujo(img, xi, yi, ri)\n",
    "            S.append(img)\n",
    "            Q.append(n)\n",
    "    S = np.array(S)\n",
    "    Q = np.array(Q)\n",
    "    randperm = np.random.permutation(len(Q))\n",
    "    return S[randperm], Q[randperm]\n",
    "\n",
    "def generar_estimulos(num_reps=40, rango_Q=np.array([0, 1, 2, 3, 4]), radio_punto=18, area_total=1200, tam_hull=3, tam_imagen=224):\n",
    "    Ss, Qs = generar_conjunto(\n",
    "        numerosidades=rango_Q,\n",
    "        repeticiones=num_reps,\n",
    "        fn_muestreo=muestrear_estandar,\n",
    "        args_muestreo={'radio_nominal': radio_punto},\n",
    "        fn_verificacion=lambda x, y, r: True,\n",
    "        fn_dibujo=dibujar_circulo,\n",
    "        tam_imagen=tam_imagen,\n",
    "        max_iter=1000,\n",
    "        nivel_fondo=50\n",
    "    )\n",
    "    Sc, Qc = generar_conjunto(\n",
    "        numerosidades=rango_Q,\n",
    "        repeticiones=num_reps,\n",
    "        fn_muestreo=muestrear_area_constante,\n",
    "        args_muestreo={'area_total': area_total},\n",
    "        fn_verificacion=verificar_densidad_control,\n",
    "        fn_dibujo=dibujar_circulo,\n",
    "        tam_imagen=tam_imagen,\n",
    "        max_iter=10_000,\n",
    "        nivel_fondo=50\n",
    "    )\n",
    "    mean_por_imagen = Sc.reshape((Sc.shape[0], -1)).mean(axis=1)\n",
    "    mean_fija = mean_por_imagen.min()\n",
    "    Sc = mean_fija * (Sc / mean_por_imagen[:, None, None, None])\n",
    "    Sss, Qss = generar_conjunto(\n",
    "        numerosidades=rango_Q,\n",
    "        repeticiones=num_reps,\n",
    "        fn_muestreo=muestrear_casco_convexo,\n",
    "        args_muestreo={'radio_nominal': radio_punto, 'tam_hull': tam_hull},\n",
    "        fn_verificacion=lambda x, y, r: True,\n",
    "        fn_dibujo=dibujar_forma_aleatoria,\n",
    "        tam_imagen=tam_imagen,\n",
    "        max_iter=1000,\n",
    "        nivel_fondo=50\n",
    "    )\n",
    "    S = np.concatenate((Ss, Sc, Sss))\n",
    "    Q = np.concatenate((Qs, Qc, Qss))\n",
    "    C = np.concatenate((\n",
    "        0 * np.ones_like(Qs),\n",
    "        1 * np.ones_like(Qc),\n",
    "        2 * np.ones_like(Qss),\n",
    "    ))\n",
    "    S = np.tile(S, (1, 1, 1, 3))\n",
    "    S = S.transpose((0, 3, 1, 2))\n",
    "    randperm = np.random.permutation(len(Q))\n",
    "    S, Q, C = S[randperm], Q[randperm], C[randperm]\n",
    "    S = S.astype(np.float32) / 255.0\n",
    "    Q = Q.astype(int)\n",
    "    C = C.astype(int)\n",
    "    return S, Q, C\n",
    "\n",
    "def anova_two_way(A, B, Y):\n",
    "    num_cells = Y.shape[1]\n",
    "\n",
    "    A_levels = np.unique(A); a = len(A_levels)\n",
    "    B_levels = np.unique(B); b = len(B_levels)\n",
    "    Y4D = np.array([[Y[(A==i)&(B==j)] for j in B_levels] for i in A_levels])\n",
    "\n",
    "    r = Y4D.shape[2]\n",
    "\n",
    "    Y = Y4D.reshape((-1, Y.shape[1]))\n",
    "\n",
    "    # only test cells (units) that are active (gave a nonzero response to at least one stimulus) to avoid division by zero errors\n",
    "    active_cells = np.where(np.abs(Y).max(axis=0)>0)[0]\n",
    "    Y4D = Y4D[:,:,:,active_cells]\n",
    "    Y = Y[:, active_cells]\n",
    "\n",
    "    N = Y.shape[0]\n",
    "\n",
    "    Y_mean = Y.mean(axis=0)\n",
    "    Y_mean_A = Y4D.mean(axis=1).mean(axis=1)\n",
    "    Y_mean_B = Y4D.mean(axis=0).mean(axis=1)\n",
    "    Y_mean_AB = Y4D.mean(axis=2)\n",
    "\n",
    "\n",
    "    SSA = r*b*np.sum((Y_mean_A - Y_mean)**2, axis=0)\n",
    "    SSB = r*a*np.sum((Y_mean_B - Y_mean)**2, axis=0)\n",
    "    SSAB = r*((Y_mean_AB - Y_mean_A[:,None] - Y_mean_B[None,:] + Y_mean)**2).sum(axis=0).sum(axis=0)\n",
    "    SSE = ((Y4D-Y_mean_AB[:,:,None])**2).sum(axis=0).sum(axis=0).sum(axis=0)\n",
    "    SST = ((Y-Y_mean)**2).sum(axis=0)\n",
    "\n",
    "    DFA = a - 1; DFB = b - 1; DFAB = DFA*DFB\n",
    "    DFE = (N-a*b); DFT = N-1\n",
    "\n",
    "    MSA = SSA / DFA\n",
    "    MSB = SSB / DFB\n",
    "    MSAB = SSAB / DFAB\n",
    "    MSE = SSE / DFE\n",
    "\n",
    "    FA = MSA / MSE\n",
    "    FB = MSB / MSE\n",
    "    FAB = MSAB / MSE\n",
    "\n",
    "    pA = np.nan*np.zeros(num_cells)\n",
    "    pB = np.nan*np.zeros(num_cells)\n",
    "    pAB = np.nan*np.zeros(num_cells)\n",
    "\n",
    "    pA[active_cells] = sp.stats.f.sf(FA, DFA, DFE)\n",
    "    pB[active_cells] = sp.stats.f.sf(FB, DFB, DFE)\n",
    "    pAB[active_cells] = sp.stats.f.sf(FAB, DFAB, DFE)\n",
    "\n",
    "    return pA, pB, pAB\n",
    "\n",
    "def average_tuning_curves(Q, H, rango_Q):\n",
    "    Qrange = np.unique(Q)\n",
    "    tuning_curves = np.array([H[Q==j,:].mean(axis=0) for j in rango_Q])\n",
    "    return tuning_curves\n",
    "\n",
    "def preferred_numerosity(Q, H, rango_Q):\n",
    "    tuning_curves = average_tuning_curves(Q, H, rango_Q)\n",
    "    pref_num = np.unique(Q)[np.argmax(tuning_curves, axis=0)]\n",
    "    return pref_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d9560-045c-42be-ae6a-aff9300be3a0",
   "metadata": {},
   "source": [
    "### Funciones de graficado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a9710-362e-4b4f-84ea-06ed0a6a525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_activaciones(activationes, capa):\n",
    "    act = activationes[capa][0]\n",
    "    n = act.shape[0]\n",
    "    \n",
    "    cols = 12\n",
    "    rows = int(math.ceil(n / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 1.2*rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n):\n",
    "      axes[i].imshow(act[i], cmap=\"gray\")\n",
    "      axes[i].axis(\"off\")\n",
    "    \n",
    "    for j in range(n, len(axes)):\n",
    "      axes[j].axis(\"off\")\n",
    "    \n",
    "    plt.suptitle(f\"Activaciones en {capa} ({n} canales de {act.shape[1]}x{act.shape[2]})\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()\n",
    "\n",
    "def visualizar_pesos(conv_layer, in_channel=0, max_plots=64):\n",
    "    W = conv_layer.weight.detach().cpu()\n",
    "    n = min(W.shape[0], max_plots)\n",
    "    cols = int(math.ceil(math.sqrt(n)))\n",
    "    rows = int(math.ceil(n / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(2*cols, 2*rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n):\n",
    "        ker = W[i, in_channel].numpy()\n",
    "        axes[i].imshow(ker, cmap=\"bwr\")\n",
    "        axes[i].axis(\"off\")\n",
    "    for j in range(n, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "    plt.suptitle(f\"Pesos {conv_layer.__class__.__name__}, canal entrada {in_channel}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a962b45f-f89d-4a5d-bbb4-d72acd5a7cc4",
   "metadata": {},
   "source": [
    "### CORnet-Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7cd6d-5394-42fa-9f4c-5cba533155a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "  \"\"\"\n",
    "  Helper module for flattening input tensor to 1-D for the use in Linear modules\n",
    "  \"\"\"\n",
    "  def forward(self, x):\n",
    "    return x.view(x.size(0), -1)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "  \"\"\"\n",
    "  Helper module that stores the current tensor. Useful for accessing by name\n",
    "  \"\"\"\n",
    "  def forward(self, x):\n",
    "    return x\n",
    "\n",
    "class CORblock_Z(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                       stride=stride, padding=kernel_size // 2)\n",
    "    self.nonlin = nn.ReLU(inplace=True)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    self.output = Identity()  # for an easy access to this block's output\n",
    "\n",
    "  def forward(self, inp):\n",
    "    x = self.conv(inp)\n",
    "    x = self.nonlin(x)\n",
    "    x = self.pool(x)\n",
    "    x = self.output(x)  # for an easy access to this block's output\n",
    "    return x\n",
    "\n",
    "\n",
    "def CORnet_Z(device = torch.device('cpu')):\n",
    "  model = nn.Sequential(collections.OrderedDict([\n",
    "    ('V1', CORblock_Z(3, 64, kernel_size=7, stride=2)),\n",
    "    ('V2', CORblock_Z(64, 128)),\n",
    "    ('V4', CORblock_Z(128, 256)),\n",
    "    ('IT', CORblock_Z(256, 512)),\n",
    "    ('decoder', nn.Sequential(collections.OrderedDict([\n",
    "      ('avgpool', nn.AdaptiveAvgPool2d(1)),\n",
    "      ('flatten', Flatten()),\n",
    "      ('linear', nn.Linear(512, 1000)),\n",
    "      ('output', Identity())\n",
    "    ])))\n",
    "  ]))\n",
    "\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "  url = 'https://s3.amazonaws.com/cornet-models/cornet_z-5c427c9c.pth'\n",
    "  ckpt_data = torch.hub.load_state_dict_from_url(url, map_location=device)\n",
    "  model.load_state_dict(ckpt_data['state_dict'])\n",
    "\n",
    "  return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf5c9e-a358-4c85-9702-70c3aa51294b",
   "metadata": {},
   "source": [
    "## Instanciación de la red\n",
    "\n",
    "Instanciá la red de CORnet-Z y fijate en su arquitectura. ¿Te suenan algunos componentes de los practicos de convolución?\n",
    "\n",
    "CORnet-Z fue entrando en una tarea de clasificación. En particular, de 1000 categorías del dataset Imagenet. Es por eso que en la capa de _decoder_ ves una capa lineal de 1000 unidades. Igual, no importa, en nuestros análisis no vamos a fijarnos en esta capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a096aa8-b1de-49fc-a923-1ac5c23780a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = encontrar_device()\n",
    "cnn = CORnet_Z(device)\n",
    "print(cnn.module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f906f2-0a18-4e97-8b07-6c69234b055d",
   "metadata": {},
   "source": [
    "Para explorar CORnet-Z, en lugar de _Imagenet_, vamos a usar _Imagenette_, un subjconjunto (sus imagenes y categorías también estan en _Imagenet_) muy reducido que nos permite por manos a la obra mucho mas rápido. Usa el siguiente componente para explorar algunas imagenes y sus categorías. CORnet-Z fue entrenado en un número de categorias 10 veces mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c9db0-7746-4732-a2de-73727c273897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Imagenette\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "\n",
    "transform = Compose([Resize((224, 224)), ToTensor()])\n",
    "dataset = Imagenette(root='data', size=\"160px\", transform=transform, download=False)\n",
    "\n",
    "@widgets.interact(idx=(0, len(dataset)-1))\n",
    "def visualizar_imagen(idx):\n",
    "    imagen, clase = dataset[idx]\n",
    "    plt.imshow(imagen.squeeze().numpy().transpose((1, 2, 0)))\n",
    "    plt.show()\n",
    "    print(f'Clase: {dataset.classes[clase][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2142a-cbc6-4cc5-b61e-372ad5ce1f7b",
   "metadata": {},
   "source": [
    "¿Que tal le va a CORnet-Z clasificando estas imágenes? Explorá alguna de ellas y fijate las probabilidades que arroja la inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df5d06-c5ab-450d-841b-460244e0bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso de normalización para usar las imagenes en CORnet-z\n",
    "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Descargamos la lista con las clases de Imagenet\n",
    "clases = descargar_clases_imagenet()\n",
    "\n",
    "@widgets.interact(idx=(0, len(dataset)-1))\n",
    "def visualizar_imagen(idx):\n",
    "    imagen, _ = dataset[idx]\n",
    "    plt.imshow(imagen.squeeze().numpy().transpose((1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "    imagen = normalize(imagen).unsqueeze(0).to(device)\n",
    "    logits = cnn(imagen)    \n",
    "    \n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    top_probs, top_idxs = torch.topk(probs, k=5, dim=1)\n",
    "    for p, idx_cls in zip(top_probs[0], top_idxs[0]):\n",
    "        clase = clases[idx_cls.item()]\n",
    "        print(f\"{clase:25s}  probabilidad = {p.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f7433-2623-45f9-acda-99840409155b",
   "metadata": {},
   "source": [
    "## Instanciación de los estímulos\n",
    "\n",
    "Vayamos al artículo de Nasr y colaboradores. ¿Qué querían investigar? Si no te queda claro, es un buen momento para discutirlo en clase.\n",
    "\n",
    "Los autores del artículo generaron estímulos en forma controlada, nosotros haremos lo mismo. Ejecutá la celda siguiente para generarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709f0ec-afbe-4aca-ab21-456893fc6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array con las numerosidades\n",
    "rango_Q = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# Semilla para replicar los resultados\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Generación de los estímulos\n",
    "S, Q, C = generar_estimulos(num_reps=40, rango_Q=rango_Q, radio_punto=18, tam_hull=3)\n",
    "\n",
    "print(\"Forma de S:\", S.shape)\n",
    "print(\"Forma de Q:\", Q.shape)\n",
    "print(\"Forma de C:\", C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52e8de-7a7f-42ff-80d1-2db18554ce81",
   "metadata": {},
   "source": [
    "La matriz `S` contiene 600 imagenes a color (RGB: un canal para el rojo, otro para el verde y el tercero para el azul) de tamaño $224 \\times 224$. Usando el siguiente componente, investigá que información comunican `Q` y `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d679e56-b245-4f43-9abf-8c95bd04b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(i=(0, len(S)-1))\n",
    "def visualizar_dataset(i):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(S[i].transpose((1, 2, 0)))\n",
    "    plt.title(f\"Q: {Q[i]}, C: {C[i]}\")\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969ead0-5b57-4648-94d3-268de59d1013",
   "metadata": {},
   "source": [
    "¿Cómo se activarán las unidades de las distintas capas de CORnet-Z al \"ver\" estas imágenes de estímulo que generaste en forma controlada? Usa el componente siguiente para explorarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8aa70a-9a9c-4dc5-a72c-954ecb351c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "\n",
    "def make_hook(name):\n",
    "    def _hook(m, i, o): activations[name] = o.detach().cpu()\n",
    "    return _hook\n",
    "\n",
    "hooks = [\n",
    "    cnn.module.V1.register_forward_hook(make_hook('V1')),\n",
    "    cnn.module.V2.register_forward_hook(make_hook('V2')),\n",
    "    cnn.module.V4.register_forward_hook(make_hook('V4')),\n",
    "    cnn.module.IT.register_forward_hook(make_hook('IT'))\n",
    "]\n",
    "\n",
    "@widgets.interact(i=(0, len(S)-1), capa=['V1', 'V2', 'V4', 'IT'])\n",
    "def simular_inferencia(i, capa):\n",
    "    activations.clear()\n",
    "    s = torch.tensor(S[i]).unsqueeze(0).to(device)\n",
    "    out = cnn(s)\n",
    "    visualizar_activaciones(activations, capa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282d884-5690-44d2-b335-e8c94701bc78",
   "metadata": {},
   "source": [
    "Ahora, lo que vamos a hacer es efectuar inferencias para las 600 imágenes al mismo tiempo, y quedarnos con todas las activaciones de la capa IT.\n",
    "\n",
    "Al imprimir la forma de la matriz, se puede apreciar que tiene un total de 25088 unidades. ¿Cómo se llega a este número?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795a522-6200-4f37-a062-350ae35254aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations.clear()\n",
    "s = torch.tensor(S).to(device)\n",
    "out = cnn(s)\n",
    "IT = activations[\"IT\"].flatten(1).numpy()\n",
    "print(IT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1543ecdf-6dc1-44c5-89fa-2f7c52e7ef42",
   "metadata": {},
   "source": [
    "A continuación, hacemos un análisis de ANOVA de dos vías para detectar aquellas unidades cuyas activaciones estan moduladas por Q (la numerosidad) independientemente de la C (la condición)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb2a82-fc98-4a98-a35b-c89e715c7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pN, pC, pNC = anova_two_way(Q, C, IT)\n",
    "anova_cells = np.where((pN<0.01) & (pNC>0.01) & (pC>0.01))[0]\n",
    "print('Número de unidades con numerosidad preferida = %i (%0.2f%%)'%(len(anova_cells), 100*len(anova_cells)/IT.shape[1]))\n",
    "\n",
    "H = IT[:, anova_cells]\n",
    "print(\"Forma de H:\", H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4f872-2c7e-4c83-b3ed-e7d88965b520",
   "metadata": {},
   "source": [
    "Con la función `preferred_numerosity` podemos calcular cual es la numerosidad preferida para cada unidad. Usá el componente interactivo para entender qué significa que una unidad pueda tener una preferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3483bc-f839-4866-b977-93ab719c283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_num = preferred_numerosity(Q, H, rango_Q)\n",
    "\n",
    "@widgets.interact(unit=(0, len(H)))\n",
    "def graficar_curva(unit):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    tc = np.array([H[(Q==q) & (C==j), unit].mean() for q in rango_Q])\n",
    "    plt.plot(rango_Q, tc, linewidth=0.5)\n",
    "\n",
    "    tc = np.array([H[(Q==q), unit].mean() for q in rango_Q])\n",
    "    err = np.array([H[(Q==q), unit].std() for q in rango_Q]) / np.sqrt(np.sum((Q==Q[0])))\n",
    "    plt.errorbar(rango_Q, tc, err, color='r', linewidth=1.5)\n",
    "\n",
    "    plt.xlabel('Numerosidad'); plt.ylabel('Activación')\n",
    "    plt.title(f'Unidad {unit} (numerosidad preferida = {pref_num[unit]})')\n",
    "    plt.xticks(rango_Q)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfa7cf-c92f-4d83-bc27-524a1bdc74a6",
   "metadata": {},
   "source": [
    "La siguiente gráfica muestra cuantas unidades prefieren cada número. ¿Coincide con lo reportado por los autores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abab148-4270-426e-ab02-9dd5ad8bcc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [np.sum(pref_num==q) for q in rango_Q]\n",
    "hist /= np.sum(hist)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.bar(rango_Q, 100*hist, width=0.8)\n",
    "plt.xlabel('Numerosidad preferida')\n",
    "plt.ylabel('Porcentaje de unidades')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b2724b-c708-4830-9f93-3b7471d531b1",
   "metadata": {},
   "source": [
    "Finalmente, podemos graficar las curvas de sintonía promedio para las unidades que prefieren cada uno de los números. ¿Coincide con lo reportado por los autores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06393ef-927a-4239-ad59-42688332c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la curva de sintonía promedio de cada unidad\n",
    "tuning_curves = average_tuning_curves(Q, H, rango_Q)\n",
    "\n",
    "# Calcular las curvas de sintonía poblacionales para cada numerosidad preferida\n",
    "tuning_mat = np.array([np.mean(tuning_curves[:,pref_num==q], axis=1) for q in rango_Q])  # una fila por cada numerosidad preferida\n",
    "tuning_err = np.array([\n",
    "    np.std(tuning_curves[:,pref_num==q], axis=1) / np.sqrt(np.sum(pref_num==q))          # error estándar para cada punto de cada curva de sintonía\n",
    "    for q in rango_Q\n",
    "])\n",
    "\n",
    "# Normalizar las curvas de sintonía poblacionales al rango 0–1\n",
    "tmmin = tuning_mat.min(axis=1)[:,None]\n",
    "tmmax = tuning_mat.max(axis=1)[:,None]\n",
    "tuning_mat = (tuning_mat - tmmin) / (tmmax - tmmin)\n",
    "tuning_err = tuning_err / (tmmax - tmmin)   # escalar el error estándar para que sea consistente con la normalización de arriba\n",
    "\n",
    "# Graficar las curvas de sintonía poblacionales en escala lineal\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1,2,1)\n",
    "for i, (tc, err) in enumerate(zip(tuning_mat, tuning_err)):\n",
    "    plt.errorbar(rango_Q, tc, err, color=colores_Q[i])\n",
    "    plt.xticks(rango_Q)\n",
    "plt.xlabel('Numerosidad')\n",
    "plt.ylabel('Actividad normalizada')\n",
    "\n",
    "# Graficar las curvas de sintonía poblacionales en escala logarítmica\n",
    "plt.subplot(1,2,2)\n",
    "for i, (tc, err) in enumerate(zip(tuning_mat, tuning_err)):\n",
    "    plt.errorbar(rango_Q+1, tc, err, color=colores_Q[i])  # desplazar el eje x por uno para evitar tomar logaritmo de cero\n",
    "    plt.xscale('log', base=2)\n",
    "    plt.xticks(ticks=rango_Q+1, labels=rango_Q)\n",
    "plt.xlabel('Numerosidad')\n",
    "plt.ylabel('Actividad normalizada')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Respuestas promedio de las unidades sintonizadas a cero ante numerosidades 1, 2 y 3\n",
    "R01 = tuning_curves[:,pref_num==0][1]\n",
    "R02 = tuning_curves[:,pref_num==0][2]\n",
    "R03 = tuning_curves[:,pref_num==0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa5ce2-44be-4e05-96d4-4c1a20ac7ac1",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "Nasr, K., Viswanathan, P. & Nieder, A. (2019). Number detectors spontaneously emerge in a deep neural network designed for visual object recognition. *Science Advances*, 5(5), eaav7903. [doi:10.1126/sciadv.aav7903](https://doi.org/10.1126/sciadv.aav7903)\n",
    "\n",
    "Kubilius, J., Schrimpf, M., Nayebi, A., Bear, D., Yamins, D. L. K & DiCarlo, J. J. (2018). CORnet: Modeling the Neural Mechanisms of Core Object Recognition. *bioRxiv*, 5(5), eaav7903. [doi:10.1101/408385](https://doi.org/10.1101/408385)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
